{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Estimating Variance of Multi-Points\n",
    "\n",
    "This notebook illustrates how MH Dropout network learns the variance of a multiple target points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from models.mhdNetwork import MhdNetwork\n",
    "from models.mlp import MLP\n",
    "\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette(\"Set1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(X_data, Y_data, model, optimizer, epochs=10, display=100, batch_size=32, hypo_count=None):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    total_steps = int(np.ceil(len(X_data) / batch_size))\n",
    "    count = 0\n",
    "    \n",
    "    indexes = torch.randperm(Y_data.shape[0])\n",
    "    X_shuffled = X_data[indexes]\n",
    "    Y_shuffled = Y_data[indexes]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for step in range(total_steps):\n",
    "            count += 1\n",
    "            x = X_shuffled[step * batch_size:step * batch_size + batch_size]\n",
    "            y = Y_shuffled[step * batch_size:step * batch_size + batch_size]\n",
    "            \n",
    "            log_loss = train_step(x, y, model, optimizer, hypo_count=hypo_count)\n",
    "            if count % display == 0:\n",
    "                print(f\"E{epoch + 1}: loss={log_loss}\")\n",
    "\n",
    "def train_step(x, y, model, optimizer, hypo_count=None):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if model.__class__.__name__ == 'mhdNetwork':\n",
    "        outputs, log_loss = model.loss(x, y=y)\n",
    "        loss = outputs['loss'].mean() \n",
    "    elif model.__class__.__name__ == 'MLP':\n",
    "        loss = model(x,y)[-1].mean()\n",
    "    else:\n",
    "        loss = model(x, y=y, hypo_count=hypo_count)['loss']\n",
    "\n",
    "    log_loss = loss.detach().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return log_loss\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "inp_dim = 2\n",
    "out_dim = 2\n",
    "dataset_sz = 1\n",
    "outputs_per_input = 5\n",
    "\n",
    "X_data = torch.normal(mean=0.0, std=torch.ones(dataset_sz, 1, inp_dim)).repeat(1, outputs_per_input, 1)\n",
    "Y_data = torch.rand(dataset_sz, outputs_per_input, out_dim)\n",
    "\n",
    "X_flat = torch.flatten(X_data, start_dim=0, end_dim=1)\n",
    "Y_flat = torch.flatten(Y_data, start_dim=0, end_dim=1)\n",
    "\n",
    "print(X_data.shape, X_flat.shape)\n",
    "print(Y_data.shape, Y_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualize labels (Y) with same input\n",
    "didx = 0 #dataset index\n",
    "\n",
    "df = pd.DataFrame(Y_data[didx].cpu().numpy(), columns=['y_1','y_2'])\n",
    "df['Type'] = 'labels'\n",
    "df['Size'] = 1.0\n",
    "\n",
    "sns.scatterplot(data=df, x='y_1', y='y_2', hue='Type')\n",
    "\n",
    "plt.title(\"Initial State\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "hid_dim         = 4\n",
    "mhd_hid_dim     = 4\n",
    "dropout_rate    = 0.5\n",
    "num_layers      = 1\n",
    "\n",
    "wta_loss        = 'vanilla'\n",
    "out_act_fn      = 'sigmoid'\n",
    "\n",
    "models = {}\n",
    "opts = {}\n",
    "\n",
    "subset_ratios = [1.0,0.95,0.9,0.75,0.5,0.25,0.01]\n",
    "\n",
    "for r in subset_ratios:\n",
    "    assert 1.0 >= r > 0.0\n",
    "\n",
    "    model_name = str(int(r*100))\n",
    "    models[model_name] = MhdNetwork(\n",
    "            inp_dim=inp_dim, \n",
    "            hid_dim=hid_dim, \n",
    "            out_dim=out_dim, \n",
    "            mhd_hid_dim=mhd_hid_dim,\n",
    "            num_layers=num_layers,\n",
    "            wta_loss=wta_loss,\n",
    "            out_act_fn=out_act_fn,\n",
    "            subset_ratio=r\n",
    "            )\n",
    "\n",
    "    #Copy weights so that initial states are the same\n",
    "    if model_name != '100':\n",
    "            models[model_name].load_state_dict(models['100'].state_dict())\n",
    "\n",
    "    opts[model_name] = torch.optim.AdamW(list(models[model_name].parameters()))\n",
    "\n",
    "\n",
    "# Check parameter counts\n",
    "param_count = sum(p.numel() for p in models['100'].parameters())\n",
    "print(param_count)\n",
    "\n",
    "max_hypos = 2 ** mhd_hid_dim - 1\n",
    "print(max_hypos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup benchmark \n",
    "mix_components   = max_hypos\n",
    "\n",
    "# Create benchmark model\n",
    "models['baseline'] = MLP(\n",
    "                    inp_dim=inp_dim, \n",
    "                    hid_dim=hid_dim, \n",
    "                    out_dim=out_dim,\n",
    "                    num_layers=3, \n",
    "                    out_act_fn=out_act_fn, \n",
    "                    dropout=0.5\n",
    "                    )\n",
    "\n",
    "# Create optimizer\n",
    "opts['baseline'] = torch.optim.AdamW(list(models['baseline'].parameters()))\n",
    "\n",
    "# Check parameter counts\n",
    "param_count = sum(p.numel() for p in models['baseline'].parameters())\n",
    "print(param_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualize initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 0.5\n",
    "\n",
    "def compute_mean_std_diffs(pred, y):\n",
    "    '''Computes through population and then averages across dimensions'''\n",
    "    pred_mean = torch.mean(pred, dim=0)\n",
    "    y_mean = torch.mean(y, dim=0)\n",
    "\n",
    "    mean_distance = torch.mean((pred_mean - y_mean) ** 2).item()\n",
    "\n",
    "    pred_std = torch.std(pred, dim=0)\n",
    "    y_std = torch.std(y, dim=0)\n",
    "\n",
    "    std_distance = torch.mean((pred_std - y_std) ** 2).item()\n",
    "\n",
    "    return mean_distance, std_distance\n",
    "\n",
    "def compute_error(pred, y):\n",
    "    '''\n",
    "    Computes average distance between nearest target of each hypothesis.\n",
    "    '''\n",
    "    y_count = y.size(0)\n",
    "    p_count = pred.size(0)\n",
    "\n",
    "    pred = pred.unsqueeze(1).repeat([1,y_count,1])\n",
    "    y = y.unsqueeze(0).repeat([p_count,1,1])\n",
    "\n",
    "    #Compute distance between each prediction and label\n",
    "    mse_error = ((pred - y) ** 2).mean(-1)\n",
    "    \n",
    "    #Find nearest target of each prediction\n",
    "    min_error = torch.min(mse_error, dim=1)[0]\n",
    "    return min_error.mean().item()\n",
    "\n",
    "def eval_model(model, X_data, Y_data, max_hypos=None):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = X_data.shape[0]\n",
    "\n",
    "    metrics = {'error': [], 'mean': [], 'std': []}\n",
    "    with torch.no_grad():\n",
    "        for idx in range(dataset_size):\n",
    "            x = X_data[idx]\n",
    "            y = Y_data[idx]\n",
    "            if model.__class__.__name__ == 'mhdNetwork':\n",
    "                model_outputs = model.sample(x=x, hypo_count=max_hypos)\n",
    "                if 'pred_sample' in model_outputs:\n",
    "                    preds = model_outputs['pred_sample']\n",
    "                else:\n",
    "                    preds = torch.flatten(model_outputs['hypotheses'], start_dim=0, end_dim=1)    \n",
    "            elif model.__class__.__name__ in ['MLP']:\n",
    "                model.train()\n",
    "                max_hypos = max_hypos if max_hypos is not None else 50\n",
    "                preds = [model.sample(x=x)['pred_sample'] for _ in range(max_hypos)]\n",
    "                preds = torch.cat(preds, dim=0)\n",
    "                \n",
    "            hypo_error = compute_error(preds, y)\n",
    "            mean, std = compute_mean_std_diffs(preds, y)\n",
    "\n",
    "            metrics['error'].append(hypo_error)\n",
    "            metrics['mean'].append(mean)\n",
    "            metrics['std'].append(std)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def sample_model(model, X_data, max_hypos, df, size, data_index):\n",
    "    model.eval()\n",
    "\n",
    "    #Prepare outputs for graph\n",
    "    x = X_data[data_index]\n",
    "    \n",
    "    if model.__class__.__name__ == 'mhdNetwork':\n",
    "        with torch.no_grad():\n",
    "            model_outputs = model.sample(x=x, hypo_count=max_hypos)\n",
    "        if 'pred_sample' in model_outputs:\n",
    "            preds = model_outputs['pred_sample']\n",
    "        else:\n",
    "            preds = torch.flatten(model_outputs['hypotheses'], start_dim=0, end_dim=1)  \n",
    "    elif model.__class__.__name__ in ['MLP']:\n",
    "        model.train()\n",
    "        with torch.no_grad():\n",
    "            preds = [model.sample(x=x)['pred_sample'] for _ in range(max_hypos)]\n",
    "            preds = torch.cat(preds, dim=0)\n",
    "\n",
    "    #Prepare inputs for graph\n",
    "    temp_df = pd.DataFrame(preds.cpu().numpy(), columns=['y_1', 'y_2'])\n",
    "    temp_df['Type'] = 'predictions'\n",
    "    temp_df['Size'] = size\n",
    "    return pd.concat([df, temp_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_container = {}\n",
    "init_dfs = {}\n",
    "data_index = 0\n",
    "\n",
    "for model_name in models.keys():\n",
    "        print(model_name)\n",
    "        metrics = eval_model(models[model_name], X_data, Y_data, max_hypos)\n",
    "\n",
    "        if model_name not in metric_container:\n",
    "                metric_container[model_name] = []\n",
    "\n",
    "        metric_container[model_name].append(metrics)\n",
    "\n",
    "        init_dfs[model_name] = sample_model(\n",
    "                models[model_name], X_data, max_hypos, df, size, data_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show initial state for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with a different size for the second row\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4)) #, gridspec_kw={'height_fractions': [2,1]})\n",
    "\n",
    "ylim_max = 1.0\n",
    "\n",
    "# Subplot 1  \n",
    "sns.scatterplot(data=init_dfs['100'], x='y_1', y='y_2', hue='Type', size='Size', ax=axes[0], legend=False)\n",
    "axes[0].set_title(\"(a) $r$=1.0\")\n",
    "axes[0].set_xlim(0,1.0)\n",
    "axes[0].set_ylim(0,ylim_max)\n",
    "\n",
    "# Subplot 2\n",
    "sns.scatterplot(data=init_dfs['75'], x='y_1', y='y_2', hue='Type', size='Size', ax=axes[1], legend=False)\n",
    "axes[1].set_title(\"(b) $r$=0.75\")\n",
    "axes[1].set_xlim(0,1.0)\n",
    "axes[1].set_ylim(0,ylim_max)\n",
    "axes[1].set_ylabel(\"\")\n",
    "axes[1].set_yticks([])\n",
    "\n",
    "# Subplot 3 \n",
    "sns.scatterplot(data=init_dfs['baseline'], x='y_1', y='y_2', hue='Type', size='Size', ax=axes[2], legend=False)\n",
    "axes[2].set_title(\"(c) baseline\")\n",
    "axes[2].set_xlim(0,1.0)\n",
    "axes[2].set_ylim(0,ylim_max)\n",
    "axes[2].set_ylabel(\"\")\n",
    "axes[2].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "display = 500\n",
    "\n",
    "for model_name in models.keys():\n",
    "    print(\"Training model={}.\".format(model_name))\n",
    "    train_loop(X_flat, Y_flat, models[model_name], opts[model_name], epochs=epochs, display=display)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_container = {}\n",
    "steady_dfs = {}\n",
    "data_index = 0\n",
    "\n",
    "for model_name in models.keys():\n",
    "\n",
    "        metrics = eval_model(models[model_name], X_data, Y_data, max_hypos)\n",
    "\n",
    "        if model_name not in metric_container:\n",
    "                metric_container[model_name] = []\n",
    "\n",
    "        metric_container[model_name].append(metrics)\n",
    "\n",
    "        steady_dfs[model_name] = sample_model(\n",
    "                models[model_name], X_data, max_hypos, df, size, data_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot comparing steady and final state\n",
    "\n",
    "model_name = 'baseline'\n",
    "\n",
    "xlim_max = 1.0\n",
    "ylim_max = 1.0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "# Steady State:\n",
    "sns.scatterplot(data=init_dfs[model_name], x='y_1', y='y_2', hue='Type', size='Size', ax=axes[0], legend=False)\n",
    "axes[0].set_title(\"(a) Initial State\")\n",
    "axes[0].set_xlim(0,xlim_max)\n",
    "axes[0].set_ylim(0,ylim_max)\n",
    "\n",
    "sns.scatterplot(data=steady_dfs[model_name], x='y_1', y='y_2', hue='Type', size='Size', ax=axes[1], legend=False)\n",
    "axes[1].set_title(\"(b) Steady State\")\n",
    "axes[1].set_xlim(0,xlim_max)\n",
    "axes[1].set_ylim(0,ylim_max)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subplot comparing steady and final state for mcr model\n",
    "\n",
    "model_name = '100'\n",
    "\n",
    "xlim_max = 1.0\n",
    "ylim_max = 1.0\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4)) \n",
    "\n",
    "# Steady State:\n",
    "sns.scatterplot(data=init_dfs[model_name], x='y_1', y='y_2', hue='Type', size='Size', ax=axes[0], legend=False)\n",
    "axes[0].set_title(\"(a) Initial State\")\n",
    "axes[0].set_xlim(0,xlim_max)\n",
    "axes[0].set_ylim(0,ylim_max)\n",
    "\n",
    "sns.scatterplot(data=steady_dfs[model_name], x='y_1', y='y_2', hue='Type', size='Size', ax=axes[1], legend=False)\n",
    "axes[1].set_title(\"(b) Steady State\")\n",
    "axes[1].set_xlim(0,xlim_max)\n",
    "axes[1].set_ylim(0,ylim_max)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_ratios_show = [1.0,0.75,.5,.01]\n",
    "\n",
    "# Create subplots with a different size for the second row\n",
    "plot_count = len(subset_ratios_show)\n",
    "fig_len = plot_count * 3\n",
    "fig, axes = plt.subplots(1, plot_count, figsize=(fig_len, 4)) #, gridspec_kw={'height_fractions': [2,1]})\n",
    "\n",
    "for idx, r in enumerate(subset_ratios_show):\n",
    "    assert 1.0 >= r > 0.0\n",
    "\n",
    "    model_name = str(int(r*100))\n",
    "\n",
    "    sns.scatterplot(data=steady_dfs[model_name], \n",
    "                    x='y_1', y='y_2', hue='Type', size='Size', ax=axes[idx], legend=False)\n",
    "    axes[idx].set_title(\"$r$={:.2f}\".format(r))\n",
    "\n",
    "\n",
    "    if idx != 0:\n",
    "        axes[idx].set_ylabel(\"\")\n",
    "        axes[idx].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment from Section 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_experiments(\n",
    "        exp_count,\n",
    "        inp_dim,\n",
    "        out_dim,\n",
    "        outputs_per_input,\n",
    "        dataset_sz,\n",
    "        hid_dim,\n",
    "        num_layers,\n",
    "        wta_loss,\n",
    "        subset_ratios,\n",
    "        epochs, \n",
    "):      \n",
    "        max_hypos = 2 ** hid_dim\n",
    "        out_act_fn      = 'sigmoid'\n",
    "        \n",
    "        metric_container = {}\n",
    "        \n",
    "        for exp_idx in range(exp_count):\n",
    "                print(\"Starting experiment {}/{}.\".format(exp_idx + 1, exp_count))\n",
    "\n",
    "                X_data = torch.normal(mean=0.0, std=torch.ones(dataset_sz, 1, inp_dim)).repeat(1, outputs_per_input, 1)\n",
    "                Y_data = torch.rand(dataset_sz, outputs_per_input, out_dim)\n",
    "                X_flat = torch.flatten(X_data, start_dim=0, end_dim=1)\n",
    "                Y_flat = torch.flatten(Y_data, start_dim=0, end_dim=1)\n",
    "\n",
    "                models = {}\n",
    "                opts = {}\n",
    "\n",
    "                #Baseline model\n",
    "                models['baseline'] = MLP(\n",
    "                                inp_dim=inp_dim, \n",
    "                                hid_dim=hid_dim, \n",
    "                                out_dim=out_dim,\n",
    "                                num_layers=num_layers, \n",
    "                                out_act_fn=out_act_fn, \n",
    "                                dropout=0.5\n",
    "                                )\n",
    "                \n",
    "                # Create optimizer\n",
    "                opts['baseline'] = torch.optim.AdamW(list(models['baseline'].parameters()))\n",
    "\n",
    "\n",
    "                for r in subset_ratios:\n",
    "                        assert 1.0 >= r > 0.0\n",
    "                        model_name = str(int(r*100))\n",
    "                        \n",
    "                        models[model_name] = MhdNetwork(\n",
    "                                inp_dim=inp_dim, \n",
    "                                hid_dim=hid_dim, \n",
    "                                out_dim=out_dim, \n",
    "                                num_layers=num_layers,\n",
    "                                wta_loss=wta_loss,\n",
    "                                out_act_fn=out_act_fn,\n",
    "                                subset_ratio=r\n",
    "                                )\n",
    "\n",
    "                        #Copy weights so that initial states are the same\n",
    "                        if model_name != '100':\n",
    "                                models[model_name].load_state_dict(models['100'].state_dict())\n",
    "\n",
    "                        opts[model_name] = torch.optim.AdamW(list(models[model_name].parameters()))\n",
    "\n",
    "                \n",
    "                for model_name in models.keys():\n",
    "\n",
    "                        train_loop(X_flat, Y_flat, models[model_name], opts[model_name], epochs=epochs, display=10000000)\n",
    "\n",
    "                        metrics = eval_model(models[model_name], X_data, Y_data)\n",
    "\n",
    "                        if model_name not in metric_container:\n",
    "                                metric_container[model_name] = {}\n",
    "\n",
    "                        for metric_name, metric_values in metrics.items():\n",
    "                                if metric_name not in metric_container[model_name]:\n",
    "                                        metric_container[model_name][metric_name] = []\n",
    "\n",
    "                                metric_container[model_name][metric_name] += metric_values\n",
    "\n",
    "        return metric_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_container = run_multiple_experiments(\n",
    "        exp_count=30,\n",
    "        inp_dim=2,\n",
    "        out_dim=2,\n",
    "        outputs_per_input=5,\n",
    "        dataset_sz=1,\n",
    "        hid_dim=4,\n",
    "        num_layers=3,\n",
    "        wta_loss='vanilla',\n",
    "        subset_ratios=[1.0,0.95,0.9,0.85,0.8,0.75,0.7,0.65,0.6,0.55,0.5,0.45,0.4,0.35,0.3,0.25,0.2,0.15,0.1,0.05,0.01],\n",
    "        epochs=10000, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data = []\n",
    "for model_name, metrics in metric_container.items():\n",
    "    error = sum(metrics['error']) / len(metrics['error'])\n",
    "    mean = sum(metrics['mean']) / len(metrics['mean'])\n",
    "    std = sum(metrics['std']) / len(metrics['std'])\n",
    "\n",
    "    print(model_name, np.mean(metrics['std']), np.std(metrics['std']))\n",
    "\n",
    "    #if model_name not in ['1','10']:\n",
    "    if model_name != 'baseline':\n",
    "        subset_ratio = int(model_name) / 100\n",
    "        for v in metrics['std']:\n",
    "            graph_data.append({'subset ratio (r)': subset_ratio, 'SDD': v, 'group': 'Stochastic WTA'})\n",
    "    else:\n",
    "        for subset_ratio in [0.01,0.5,1.0]:\n",
    "            for v in metrics['std']:\n",
    "                graph_data.append({'subset ratio (r)': subset_ratio, 'SDD': v, 'group': 'MC dropout'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style('ticks')\n",
    "sns.set_palette(\"Set1\")\n",
    "\n",
    "graph_df = pd.DataFrame(graph_data)\n",
    "ax = sns.lineplot(graph_df, x='subset ratio (r)', y='SDD', hue='group', errorbar=('ci', 95)) \n",
    "plt.yscale('log')\n",
    "plt.ylabel('log SSD')\n",
    "ax.lines[0].set_linestyle(\"--\")\n",
    "\n",
    "sns.despine()\n",
    "plt.legend(title=None, frameon=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mixnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
